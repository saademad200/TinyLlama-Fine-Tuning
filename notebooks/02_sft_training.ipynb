{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Supervised Fine-Tuning (SFT) with LoRA/qLoRA\n\n**Two trials with different configurations:**\n- Trial 1: Conservative (LoRA rank=8, full precision)\n- Trial 2: Aggressive (qLoRA rank=32, 4-bit)\n\n**Output:** JSON result files for each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets transformers peft trl bitsandbytes accelerate sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "os.makedirs('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('data/sft_dataset')\n",
    "print(f\"Train: {len(dataset['train'])}, Val: {len(dataset['test'])}\")\n",
    "print('Sample:', dataset['train'][0]['text'][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Base Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "print(f\"Loaded tokenizer with vocab size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trial 1: Conservative LoRA (rank=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 1 Configuration\n",
    "TRIAL1_CONFIG = {\n",
    "    \"r\": 8,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"target_modules\": [\"q_proj\", \"v_proj\"],\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\"\n",
    "}\n",
    "\n",
    "TRIAL1_TRAINING = {\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"warmup_ratio\": 0.03,\n",
    "    \"max_seq_length\": 512,\n",
    "    \"quantization\": \"none\"\n",
    "}\n",
    "\n",
    "# Load model (full precision for Trial 1)\n",
    "model_t1 = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "lora_config_t1 = LoraConfig(**TRIAL1_CONFIG)\n",
    "model_t1 = get_peft_model(model_t1, lora_config_t1)\n",
    "model_t1.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments for Trial 1\n",
    "training_args_t1 = TrainingArguments(\n",
    "    output_dir=\"./outputs/sft_trial1\",\n",
    "    num_train_epochs=TRIAL1_TRAINING[\"num_train_epochs\"],\n",
    "    per_device_train_batch_size=TRIAL1_TRAINING[\"per_device_train_batch_size\"],\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=TRIAL1_TRAINING[\"gradient_accumulation_steps\"],\n",
    "    learning_rate=TRIAL1_TRAINING[\"learning_rate\"],\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=TRIAL1_TRAINING[\"warmup_ratio\"],\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=25,\n",
    "    save_steps=200,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer_t1 = SFTTrainer(\n",
    "    model=model_t1,\n",
    "    args=training_args_t1,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=TRIAL1_TRAINING[\"max_seq_length\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Trial 1 and save JSON results\n",
    "print('Starting SFT Trial 1...')\n",
    "start_time = time.time()\n",
    "trainer_t1.train()\n",
    "training_time_t1 = time.time() - start_time\n",
    "\n",
    "# Save model\n",
    "trainer_t1.save_model('./outputs/sft_trial1/final')\n",
    "\n",
    "# Get final metrics\n",
    "final_metrics_t1 = trainer_t1.state.log_history\n",
    "\n",
    "# Create results JSON\n",
    "sft_trial1_results = {\n",
    "    \"trial_name\": \"sft_trial1\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"dataset\": \"databricks/databricks-dolly-15k\",\n",
    "    \"dataset_size\": len(dataset[\"train\"]),\n",
    "    \"lora_config\": TRIAL1_CONFIG,\n",
    "    \"training_config\": TRIAL1_TRAINING,\n",
    "    \"training_time_seconds\": training_time_t1,\n",
    "    \"training_time_minutes\": training_time_t1 / 60,\n",
    "    \"final_train_loss\": [l for l in final_metrics_t1 if 'loss' in l and 'eval' not in str(l)][-1].get('loss') if final_metrics_t1 else None,\n",
    "    \"final_eval_loss\": [l for l in final_metrics_t1 if 'eval_loss' in l][-1].get('eval_loss') if [l for l in final_metrics_t1 if 'eval_loss' in l] else None,\n",
    "    \"training_log\": final_metrics_t1,\n",
    "    \"output_dir\": \"./outputs/sft_trial1/final\"\n",
    "}\n",
    "\n",
    "# Save JSON\n",
    "with open('results/sft_trial1_results.json', 'w') as f:\n",
    "    json.dump(sft_trial1_results, f, indent=2)\n",
    "print(f'\\nTrial 1 complete! Results saved to results/sft_trial1_results.json')\n",
    "print(f'Training time: {training_time_t1/60:.2f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trial 2: Aggressive qLoRA (rank=32, 4-bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "del model_t1, trainer_t1\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Trial 2: 4-bit quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load quantized model\n",
    "model_t2 = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model_t2 = prepare_model_for_kbit_training(model_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial 2 Configuration\n",
    "TRIAL2_CONFIG = {\n",
    "    \"r\": 32,\n",
    "    \"lora_alpha\": 64,\n",
    "    \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\"\n",
    "}\n",
    "\n",
    "TRIAL2_TRAINING = {\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"gradient_accumulation_steps\": 8,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"warmup_ratio\": 0.05,\n",
    "    \"max_seq_length\": 512,\n",
    "    \"quantization\": \"4bit-nf4\"\n",
    "}\n",
    "\n",
    "lora_config_t2 = LoraConfig(**TRIAL2_CONFIG)\n",
    "model_t2 = get_peft_model(model_t2, lora_config_t2)\n",
    "model_t2.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments for Trial 2\n",
    "training_args_t2 = TrainingArguments(\n",
    "    output_dir=\"./outputs/sft_trial2\",\n",
    "    num_train_epochs=TRIAL2_TRAINING[\"num_train_epochs\"],\n",
    "    per_device_train_batch_size=TRIAL2_TRAINING[\"per_device_train_batch_size\"],\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=TRIAL2_TRAINING[\"gradient_accumulation_steps\"],\n",
    "    learning_rate=TRIAL2_TRAINING[\"learning_rate\"],\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=TRIAL2_TRAINING[\"warmup_ratio\"],\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=25,\n",
    "    save_steps=200,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer_t2 = SFTTrainer(\n",
    "    model=model_t2,\n",
    "    args=training_args_t2,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=TRIAL2_TRAINING[\"max_seq_length\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Trial 2 and save JSON results\n",
    "print('Starting SFT Trial 2...')\n",
    "start_time = time.time()\n",
    "trainer_t2.train()\n",
    "training_time_t2 = time.time() - start_time\n",
    "\n",
    "# Save model\n",
    "trainer_t2.save_model('./outputs/sft_trial2/final')\n",
    "\n",
    "# Get final metrics\n",
    "final_metrics_t2 = trainer_t2.state.log_history\n",
    "\n",
    "# Create results JSON\n",
    "sft_trial2_results = {\n",
    "    \"trial_name\": \"sft_trial2\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"dataset\": \"databricks/databricks-dolly-15k\",\n",
    "    \"dataset_size\": len(dataset[\"train\"]),\n",
    "    \"lora_config\": TRIAL2_CONFIG,\n",
    "    \"training_config\": TRIAL2_TRAINING,\n",
    "    \"training_time_seconds\": training_time_t2,\n",
    "    \"training_time_minutes\": training_time_t2 / 60,\n",
    "    \"final_train_loss\": [l for l in final_metrics_t2 if 'loss' in l and 'eval' not in str(l)][-1].get('loss') if final_metrics_t2 else None,\n",
    "    \"final_eval_loss\": [l for l in final_metrics_t2 if 'eval_loss' in l][-1].get('eval_loss') if [l for l in final_metrics_t2 if 'eval_loss' in l] else None,\n",
    "    \"training_log\": final_metrics_t2,\n",
    "    \"output_dir\": \"./outputs/sft_trial2/final\"\n",
    "}\n",
    "\n",
    "with open('results/sft_trial2_results.json', 'w') as f:\n",
    "    json.dump(sft_trial2_results, f, indent=2)\n",
    "print(f'\\nTrial 2 complete! Results saved to results/sft_trial2_results.json')\n",
    "print(f'Training time: {training_time_t2/60:.2f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare SFT Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and compare results\n",
    "with open('results/sft_trial1_results.json') as f:\n",
    "    t1 = json.load(f)\n",
    "with open('results/sft_trial2_results.json') as f:\n",
    "    t2 = json.load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SFT TRIALS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Metric':<25} {'Trial 1':<15} {'Trial 2':<15}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'LoRA Rank':<25} {t1['lora_config']['r']:<15} {t2['lora_config']['r']:<15}\")\n",
    "print(f\"{'Quantization':<25} {t1['training_config']['quantization']:<15} {t2['training_config']['quantization']:<15}\")\n",
    "print(f\"{'Learning Rate':<25} {t1['training_config']['learning_rate']:<15} {t2['training_config']['learning_rate']:<15}\")\n",
    "print(f\"{'Epochs':<25} {t1['training_config']['num_train_epochs']:<15} {t2['training_config']['num_train_epochs']:<15}\")\n",
    "print(f\"{'Final Train Loss':<25} {t1['final_train_loss']:<15.4f} {t2['final_train_loss']:<15.4f}\")\n",
    "print(f\"{'Final Eval Loss':<25} {t1['final_eval_loss']:<15.4f} {t2['final_eval_loss']:<15.4f}\")\n",
    "print(f\"{'Training Time (min)':<25} {t1['training_time_minutes']:<15.1f} {t2['training_time_minutes']:<15.1f}\")\n",
    "\n",
    "# Determine best model\n",
    "best = \"sft_trial1\" if t1['final_eval_loss'] < t2['final_eval_loss'] else \"sft_trial2\"\n",
    "print(f\"\\nBest model based on eval loss: {best}\")\n",
    "print(f\"\\nUse this for DPO training: ./outputs/{best}/final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}