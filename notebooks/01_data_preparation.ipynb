{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Data Preparation for TinyLlama Fine-Tuning\n\n**Datasets:**\n- SFT: `databricks/databricks-dolly-15k`\n- DPO: `argilla/distilabel-intel-orca-dpo-pairs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets transformers peft trl bitsandbytes accelerate sentencepiece sacrebleu nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "SEED = 42\n",
    "MAX_SFT = 10000\n",
    "MAX_DPO = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dolly-15k Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolly = load_dataset('databricks/databricks-dolly-15k', split='train')\n",
    "print(f'Samples: {len(dolly)}, Columns: {dolly.column_names}')\n",
    "dolly[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category distribution\n",
    "for cat, cnt in Counter(dolly['category']).most_common():\n",
    "    print(f'{cat}: {cnt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Tokenizer and Define Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('TinyLlama/TinyLlama-1.1B-Chat-v1.0')\n",
    "print(f'Vocab size: {tokenizer.vocab_size}')\n",
    "print(f'EOS token: {tokenizer.eos_token}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_TOK = \"<|system|>\"\n",
    "USR_TOK = \"<|user|>\"\n",
    "AST_TOK = \"<|assistant|>\"\n",
    "EOS_TOK = \"</s>\"\n",
    "SYSTEM_MSG = \"You are a helpful assistant.\"\n",
    "\n",
    "def format_sft(example):\n",
    "    \"\"\"Format for SFT training.\"\"\"\n",
    "    instr = example['instruction']\n",
    "    ctx = example.get('context', '')\n",
    "    resp = example['response']\n",
    "    user_content = f\"{instr}\\n\\nContext: {ctx}\" if ctx.strip() else instr\n",
    "    text = f\"{SYS_TOK}\\n{SYSTEM_MSG}{EOS_TOK}\\n{USR_TOK}\\n{user_content}{EOS_TOK}\\n{AST_TOK}\\n{resp}{EOS_TOK}\"\n",
    "    return {\"text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply formatting\n",
    "sft_data = dolly.shuffle(seed=SEED).select(range(min(MAX_SFT, len(dolly))))\n",
    "sft_data = sft_data.map(format_sft)\n",
    "print(f'Formatted {len(sft_data)} samples')\n",
    "print('Sample:\\n' + sft_data[0]['text'][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_split = sft_data.train_test_split(test_size=0.1, seed=SEED)\n",
    "print(f'Train: {len(sft_split[\"train\"])}, Val: {len(sft_split[\"test\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load DPO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo = load_dataset('argilla/distilabel-intel-orca-dpo-pairs', split='train')\n",
    "print(f'DPO samples: {len(dpo)}')\n",
    "print(f'Columns: {dpo.column_names}')\n",
    "dpo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format DPO data\n",
    "def format_dpo(example):\n",
    "    prompt = example['input']\n",
    "    chosen = example['chosen']\n",
    "    rejected = example['rejected']\n",
    "    return {'prompt': prompt, 'chosen': chosen, 'rejected': rejected}\n",
    "\n",
    "dpo_data = dpo.shuffle(seed=SEED).select(range(min(MAX_DPO, len(dpo))))\n",
    "dpo_data = dpo_data.map(format_dpo)\n",
    "print(f'Formatted {len(dpo_data)} DPO pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Processed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_split.save_to_disk('data/sft_dataset')\n",
    "dpo_data.save_to_disk('data/dpo_dataset')\n",
    "print('Datasets saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}