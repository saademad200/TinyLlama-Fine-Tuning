{
  "trial_name": "dpo_trial1",
  "timestamp": "2025-12-25T17:50:47.367802",
  "base_sft_model": "./outputs/outputs/sft_trial2",
  "dataset": "argilla/distilabel-intel-orca-dpo-pairs",
  "dataset_size": 4500,
  "dpo_config": {
    "beta": 0.1,
    "num_train_epochs": 2,
    "learning_rate": 5e-05,
    "per_device_train_batch_size": 2,
    "gradient_accumulation_steps": 4,
    "max_length": 512,
    "max_prompt_length": 256
  },
  "lora_config": {
    "r": 8,
    "lora_alpha": 16,
    "target_modules": [
      "q_proj",
      "v_proj"
    ],
    "lora_dropout": 0.05
  },
  "training_time_seconds": 13573.966508626938,
  "training_time_minutes": 226.2327751437823,
  "final_train_loss": 0.2355,
  "final_eval_loss": 0.47788140177726746,
  "training_log": [
    {
      "loss": 0.6482,
      "grad_norm": 4.7482075691223145,
      "learning_rate": 2.105263157894737e-05,
      "rewards/chosen": -1.2563897371292114,
      "rewards/rejected": -1.9509882926940918,
      "rewards/accuracies": 0.7174999713897705,
      "rewards/margins": 0.6945987939834595,
      "logps/chosen": -252.80746459960938,
      "logps/rejected": -297.7107849121094,
      "logits/chosen": -2.0471744537353516,
      "logits/rejected": -2.0162124633789062,
      "epoch": 0.08888888888888889,
      "step": 25
    },
    {
      "loss": 0.577,
      "grad_norm": 8.323320388793945,
      "learning_rate": 4.298245614035088e-05,
      "rewards/chosen": -1.287610650062561,
      "rewards/rejected": -2.480494499206543,
      "rewards/accuracies": 0.7825000286102295,
      "rewards/margins": 1.1928837299346924,
      "logps/chosen": -258.7378234863281,
      "logps/rejected": -308.11114501953125,
      "logits/chosen": -1.9833853244781494,
      "logits/rejected": -1.956262469291687,
      "epoch": 0.17777777777777778,
      "step": 50
    },
    {
      "loss": 0.5723,
      "grad_norm": 6.302419662475586,
      "learning_rate": 4.986142335149978e-05,
      "rewards/chosen": -1.0468580722808838,
      "rewards/rejected": -2.206988573074341,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/margins": 1.1601303815841675,
      "logps/chosen": -258.2416076660156,
      "logps/rejected": -294.46807861328125,
      "logits/chosen": -2.1629061698913574,
      "logits/rejected": -2.133420467376709,
      "epoch": 0.26666666666666666,
      "step": 75
    },
    {
      "loss": 0.5049,
      "grad_norm": 6.5261993408203125,
      "learning_rate": 4.9158140150143484e-05,
      "rewards/chosen": -0.8868204355239868,
      "rewards/rejected": -2.264488458633423,
      "rewards/accuracies": 0.8125,
      "rewards/margins": 1.3776679039001465,
      "logps/chosen": -267.04046630859375,
      "logps/rejected": -301.8951721191406,
      "logits/chosen": -2.2594988346099854,
      "logits/rejected": -2.236215591430664,
      "epoch": 0.35555555555555557,
      "step": 100
    },
    {
      "eval_loss": 0.49455320835113525,
      "eval_runtime": 201.5775,
      "eval_samples_per_second": 2.48,
      "eval_steps_per_second": 0.62,
      "eval_rewards/chosen": -0.7902846336364746,
      "eval_rewards/rejected": -2.247049570083618,
      "eval_rewards/accuracies": 0.8220000267028809,
      "eval_rewards/margins": 1.456764817237854,
      "eval_logps/chosen": -256.0079650878906,
      "eval_logps/rejected": -294.08502197265625,
      "eval_logits/chosen": -2.280531644821167,
      "eval_logits/rejected": -2.268686294555664,
      "epoch": 0.35555555555555557,
      "step": 100
    },
    {
      "loss": 0.4222,
      "grad_norm": 8.169764518737793,
      "learning_rate": 4.787628326959747e-05,
      "rewards/chosen": -0.6929185390472412,
      "rewards/rejected": -2.5702104568481445,
      "rewards/accuracies": 0.8525000214576721,
      "rewards/margins": 1.8772920370101929,
      "logps/chosen": -259.8564147949219,
      "logps/rejected": -316.7919616699219,
      "logits/chosen": -2.2764298915863037,
      "logits/rejected": -2.2707433700561523,
      "epoch": 0.4444444444444444,
      "step": 125
    },
    {
      "loss": 0.5428,
      "grad_norm": 6.7226080894470215,
      "learning_rate": 4.604655245110684e-05,
      "rewards/chosen": -0.8810298442840576,
      "rewards/rejected": -2.4590742588043213,
      "rewards/accuracies": 0.8174999952316284,
      "rewards/margins": 1.5780445337295532,
      "logps/chosen": -280.272216796875,
      "logps/rejected": -308.8316650390625,
      "logits/chosen": -2.4084677696228027,
      "logits/rejected": -2.40047287940979,
      "epoch": 0.5333333333333333,
      "step": 150
    },
    {
      "loss": 0.5096,
      "grad_norm": 7.799130916595459,
      "learning_rate": 4.371276870427753e-05,
      "rewards/chosen": -0.7735928893089294,
      "rewards/rejected": -2.3865714073181152,
      "rewards/accuracies": 0.8299999833106995,
      "rewards/margins": 1.612978458404541,
      "logps/chosen": -271.8965148925781,
      "logps/rejected": -320.1363525390625,
      "logits/chosen": -2.5109448432922363,
      "logits/rejected": -2.477762222290039,
      "epoch": 0.6222222222222222,
      "step": 175
    },
    {
      "loss": 0.4429,
      "grad_norm": 8.046988487243652,
      "learning_rate": 4.09308248188874e-05,
      "rewards/chosen": -0.6995315551757812,
      "rewards/rejected": -2.369718074798584,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/margins": 1.6701865196228027,
      "logps/chosen": -271.9660949707031,
      "logps/rejected": -318.3771667480469,
      "logits/chosen": -2.568166732788086,
      "logits/rejected": -2.5352623462677,
      "epoch": 0.7111111111111111,
      "step": 200
    },
    {
      "eval_loss": 0.47282496094703674,
      "eval_runtime": 201.3592,
      "eval_samples_per_second": 2.483,
      "eval_steps_per_second": 0.621,
      "eval_rewards/chosen": -0.7308834195137024,
      "eval_rewards/rejected": -2.4025416374206543,
      "eval_rewards/accuracies": 0.8299999833106995,
      "eval_rewards/margins": 1.6716583967208862,
      "eval_logps/chosen": -255.4139404296875,
      "eval_logps/rejected": -295.6399230957031,
      "eval_logits/chosen": -2.5428218841552734,
      "eval_logits/rejected": -2.5240883827209473,
      "epoch": 0.7111111111111111,
      "step": 200
    },
    {
      "loss": 0.5038,
      "grad_norm": 5.306082248687744,
      "learning_rate": 3.776734676444678e-05,
      "rewards/chosen": -0.8394500017166138,
      "rewards/rejected": -2.45326828956604,
      "rewards/accuracies": 0.8100000023841858,
      "rewards/margins": 1.6138184070587158,
      "logps/chosen": -266.4014892578125,
      "logps/rejected": -303.3155822753906,
      "logits/chosen": -2.5162291526794434,
      "logits/rejected": -2.4833414554595947,
      "epoch": 0.8,
      "step": 225
    },
    {
      "loss": 0.4261,
      "grad_norm": 7.02311372756958,
      "learning_rate": 3.429809803622551e-05,
      "rewards/chosen": -0.6369211673736572,
      "rewards/rejected": -2.35518741607666,
      "rewards/accuracies": 0.8475000262260437,
      "rewards/margins": 1.7182658910751343,
      "logps/chosen": -255.28892517089844,
      "logps/rejected": -289.9724426269531,
      "logits/chosen": -2.5288703441619873,
      "logits/rejected": -2.506408452987671,
      "epoch": 0.8888888888888888,
      "step": 250
    },
    {
      "loss": 0.4661,
      "grad_norm": 7.487667083740234,
      "learning_rate": 3.060616516274921e-05,
      "rewards/chosen": -0.6946902275085449,
      "rewards/rejected": -2.6995606422424316,
      "rewards/accuracies": 0.8100000023841858,
      "rewards/margins": 2.0048704147338867,
      "logps/chosen": -265.62921142578125,
      "logps/rejected": -315.9886779785156,
      "logits/chosen": -2.5320866107940674,
      "logits/rejected": -2.483384609222412,
      "epoch": 0.9777777777777777,
      "step": 275
    },
    {
      "loss": 0.3101,
      "grad_norm": 1.7031596899032593,
      "learning_rate": 2.6779967830825454e-05,
      "rewards/chosen": -0.45883938670158386,
      "rewards/rejected": -2.6218812465667725,
      "rewards/accuracies": 0.8814433217048645,
      "rewards/margins": 2.1630420684814453,
      "logps/chosen": -239.2298583984375,
      "logps/rejected": -288.3731689453125,
      "logits/chosen": -2.5416228771209717,
      "logits/rejected": -2.4978883266448975,
      "epoch": 1.064,
      "step": 300
    },
    {
      "eval_loss": 0.46233654022216797,
      "eval_runtime": 201.1065,
      "eval_samples_per_second": 2.486,
      "eval_steps_per_second": 0.622,
      "eval_rewards/chosen": -0.6970784664154053,
      "eval_rewards/rejected": -2.4264776706695557,
      "eval_rewards/accuracies": 0.8299999833106995,
      "eval_rewards/margins": 1.7293994426727295,
      "eval_logps/chosen": -255.07591247558594,
      "eval_logps/rejected": -295.8793029785156,
      "eval_logits/chosen": -2.522965431213379,
      "eval_logits/rejected": -2.4943735599517822,
      "epoch": 1.064,
      "step": 300
    },
    {
      "loss": 0.2259,
      "grad_norm": 1.853379249572754,
      "learning_rate": 2.2911141284470466e-05,
      "rewards/chosen": -0.38538211584091187,
      "rewards/rejected": -3.032543659210205,
      "rewards/accuracies": 0.9049999713897705,
      "rewards/margins": 2.6471612453460693,
      "logps/chosen": -259.24322509765625,
      "logps/rejected": -313.7318420410156,
      "logits/chosen": -2.556706666946411,
      "logits/rejected": -2.494250535964966,
      "epoch": 1.1528888888888889,
      "step": 325
    },
    {
      "loss": 0.242,
      "grad_norm": 3.0361123085021973,
      "learning_rate": 1.909234171307466e-05,
      "rewards/chosen": -0.43178677558898926,
      "rewards/rejected": -3.075730562210083,
      "rewards/accuracies": 0.9175000190734863,
      "rewards/margins": 2.6439437866210938,
      "logps/chosen": -272.6014709472656,
      "logps/rejected": -312.7577819824219,
      "logits/chosen": -2.5310983657836914,
      "logits/rejected": -2.4844422340393066,
      "epoch": 1.2417777777777779,
      "step": 350
    },
    {
      "loss": 0.2766,
      "grad_norm": 3.234401226043701,
      "learning_rate": 1.5415027188508573e-05,
      "rewards/chosen": -0.4968911409378052,
      "rewards/rejected": -2.977574348449707,
      "rewards/accuracies": 0.8824999928474426,
      "rewards/margins": 2.4806830883026123,
      "logps/chosen": -254.0732421875,
      "logps/rejected": -308.8860778808594,
      "logits/chosen": -2.56203556060791,
      "logits/rejected": -2.5058727264404297,
      "epoch": 1.3306666666666667,
      "step": 375
    },
    {
      "loss": 0.2686,
      "grad_norm": 4.894780158996582,
      "learning_rate": 1.1967267296460208e-05,
      "rewards/chosen": -0.4119156002998352,
      "rewards/rejected": -2.64748477935791,
      "rewards/accuracies": 0.8799999952316284,
      "rewards/margins": 2.235569477081299,
      "logps/chosen": -271.15362548828125,
      "logps/rejected": -301.989990234375,
      "logits/chosen": -2.6028456687927246,
      "logits/rejected": -2.561824083328247,
      "epoch": 1.4195555555555557,
      "step": 400
    },
    {
      "eval_loss": 0.463008850812912,
      "eval_runtime": 201.0928,
      "eval_samples_per_second": 2.486,
      "eval_steps_per_second": 0.622,
      "eval_rewards/chosen": -0.7243242263793945,
      "eval_rewards/rejected": -2.376685380935669,
      "eval_rewards/accuracies": 0.8240000009536743,
      "eval_rewards/margins": 1.6523611545562744,
      "eval_logps/chosen": -255.34837341308594,
      "eval_logps/rejected": -295.38140869140625,
      "eval_logits/chosen": -2.5975475311279297,
      "eval_logits/rejected": -2.5744619369506836,
      "epoch": 1.4195555555555557,
      "step": 400
    },
    {
      "loss": 0.2027,
      "grad_norm": 3.4705145359039307,
      "learning_rate": 8.831633920083968e-06,
      "rewards/chosen": -0.3247501850128174,
      "rewards/rejected": -3.033397912979126,
      "rewards/accuracies": 0.9300000071525574,
      "rewards/margins": 2.7086477279663086,
      "logps/chosen": -240.23553466796875,
      "logps/rejected": -320.41522216796875,
      "logits/chosen": -2.631201982498169,
      "logits/rejected": -2.5816526412963867,
      "epoch": 1.5084444444444445,
      "step": 425
    },
    {
      "loss": 0.2258,
      "grad_norm": 3.648101568222046,
      "learning_rate": 6.083223690489901e-06,
      "rewards/chosen": -0.37547385692596436,
      "rewards/rejected": -2.9127602577209473,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/margins": 2.5372862815856934,
      "logps/chosen": -273.571533203125,
      "logps/rejected": -314.4043884277344,
      "logits/chosen": -2.545729637145996,
      "logits/rejected": -2.5154805183410645,
      "epoch": 1.5973333333333333,
      "step": 450
    },
    {
      "loss": 0.2118,
      "grad_norm": 3.264002561569214,
      "learning_rate": 3.7878594652562575e-06,
      "rewards/chosen": -0.4179617166519165,
      "rewards/rejected": -3.021956443786621,
      "rewards/accuracies": 0.9175000190734863,
      "rewards/margins": 2.603994846343994,
      "logps/chosen": -263.60943603515625,
      "logps/rejected": -318.44085693359375,
      "logits/chosen": -2.5447566509246826,
      "logits/rejected": -2.496549129486084,
      "epoch": 1.6862222222222223,
      "step": 475
    },
    {
      "loss": 0.2284,
      "grad_norm": 3.382830858230591,
      "learning_rate": 2.0005139085293945e-06,
      "rewards/chosen": -0.46671414375305176,
      "rewards/rejected": -3.1368939876556396,
      "rewards/accuracies": 0.925000011920929,
      "rewards/margins": 2.6701793670654297,
      "logps/chosen": -276.1896057128906,
      "logps/rejected": -322.8406982421875,
      "logits/chosen": -2.572312593460083,
      "logits/rejected": -2.548673152923584,
      "epoch": 1.775111111111111,
      "step": 500
    },
    {
      "eval_loss": 0.47788140177726746,
      "eval_runtime": 200.958,
      "eval_samples_per_second": 2.488,
      "eval_steps_per_second": 0.622,
      "eval_rewards/chosen": -0.8165611028671265,
      "eval_rewards/rejected": -2.681063413619995,
      "eval_rewards/accuracies": 0.8240000009536743,
      "eval_rewards/margins": 1.8645025491714478,
      "eval_logps/chosen": -256.2707214355469,
      "eval_logps/rejected": -298.4251708984375,
      "eval_logits/chosen": -2.561843156814575,
      "eval_logits/rejected": -2.535841703414917,
      "epoch": 1.775111111111111,
      "step": 500
    },
    {
      "loss": 0.2435,
      "grad_norm": 1.9519739151000977,
      "learning_rate": 7.639929270683438e-07,
      "rewards/chosen": -0.48711004853248596,
      "rewards/rejected": -3.189864158630371,
      "rewards/accuracies": 0.9100000262260437,
      "rewards/margins": 2.702754020690918,
      "logps/chosen": -248.10304260253906,
      "logps/rejected": -311.9141845703125,
      "logits/chosen": -2.5511481761932373,
      "logits/rejected": -2.487654685974121,
      "epoch": 1.8639999999999999,
      "step": 525
    },
    {
      "loss": 0.2355,
      "grad_norm": 1.926115870475769,
      "learning_rate": 1.0791049319021085e-07,
      "rewards/chosen": -0.4122983515262604,
      "rewards/rejected": -3.036020278930664,
      "rewards/accuracies": 0.9225000143051147,
      "rewards/margins": 2.6237218379974365,
      "logps/chosen": -247.7082061767578,
      "logps/rejected": -306.5340576171875,
      "logits/chosen": -2.6071741580963135,
      "logits/rejected": -2.5482378005981445,
      "epoch": 1.952888888888889,
      "step": 550
    },
    {
      "train_runtime": 13573.3219,
      "train_samples_per_second": 0.663,
      "train_steps_per_second": 0.042,
      "total_flos": 0.0,
      "train_loss": 0.37276110327835627,
      "epoch": 2.0,
      "step": 564
    }
  ],
  "output_dir": "./outputs/dpo_trial1/final"
}