{
  "trial_name": "dpo_trial2",
  "timestamp": "2025-12-26T16:44:31.593353",
  "base_sft_model": "./outputs/outputs/sft_trial2",
  "dataset": "argilla/distilabel-intel-orca-dpo-pairs",
  "dataset_size": 4500,
  "dpo_config": {
    "beta": 0.5,
    "num_train_epochs": 3,
    "learning_rate": 1e-05,
    "per_device_train_batch_size": 2,
    "gradient_accumulation_steps": 8,
    "max_length": 512,
    "max_prompt_length": 256
  },
  "lora_config": {
    "r": 16,
    "lora_alpha": 32,
    "target_modules": [
      "q_proj",
      "k_proj",
      "v_proj",
      "o_proj"
    ],
    "lora_dropout": 0.1
  },
  "training_time_seconds": 21498.346044540405,
  "training_time_minutes": 358.30576740900676,
  "final_train_loss": 0.6526,
  "final_eval_loss": 1.092212438583374,
  "training_log": [
    {
      "loss": 1.8319,
      "grad_norm": 27.036867141723633,
      "learning_rate": 5.58139534883721e-06,
      "rewards/chosen": -6.1637067794799805,
      "rewards/rejected": -9.337139129638672,
      "rewards/accuracies": 0.7087500095367432,
      "rewards/margins": 3.1734321117401123,
      "logps/chosen": -255.38006591796875,
      "logps/rejected": -299.4278564453125,
      "logits/chosen": -2.0472664833068848,
      "logits/rejected": -2.0264804363250732,
      "epoch": 0.17777777777777778,
      "step": 25
    },
    {
      "loss": 1.8708,
      "grad_norm": 29.66212272644043,
      "learning_rate": 9.993849845741525e-06,
      "rewards/chosen": -5.8080854415893555,
      "rewards/rejected": -8.416533470153809,
      "rewards/accuracies": 0.6775000095367432,
      "rewards/margins": 2.608447313308716,
      "logps/chosen": -264.5888366699219,
      "logps/rejected": -292.6573486328125,
      "logits/chosen": -2.1263139247894287,
      "logits/rejected": -2.121055841445923,
      "epoch": 0.35555555555555557,
      "step": 50
    },
    {
      "loss": 1.6136,
      "grad_norm": 26.96040916442871,
      "learning_rate": 9.836688231149593e-06,
      "rewards/chosen": -4.922693252563477,
      "rewards/rejected": -8.269157409667969,
      "rewards/accuracies": 0.6850000023841858,
      "rewards/margins": 3.346463918685913,
      "logps/chosen": -272.0399169921875,
      "logps/rejected": -304.2037048339844,
      "logits/chosen": -2.1425082683563232,
      "logits/rejected": -2.160611152648926,
      "epoch": 0.5333333333333333,
      "step": 75
    },
    {
      "loss": 1.4438,
      "grad_norm": 28.968093872070312,
      "learning_rate": 9.473646649103819e-06,
      "rewards/chosen": -4.239091396331787,
      "rewards/rejected": -7.38557243347168,
      "rewards/accuracies": 0.7037500143051147,
      "rewards/margins": 3.146481513977051,
      "logps/chosen": -273.0438537597656,
      "logps/rejected": -310.2464904785156,
      "logits/chosen": -2.261869430541992,
      "logits/rejected": -2.2520644664764404,
      "epoch": 0.7111111111111111,
      "step": 100
    },
    {
      "eval_loss": 1.3760136365890503,
      "eval_runtime": 216.6832,
      "eval_samples_per_second": 2.308,
      "eval_steps_per_second": 0.577,
      "eval_rewards/chosen": -3.8966009616851807,
      "eval_rewards/rejected": -7.131871700286865,
      "eval_rewards/accuracies": 0.7279999852180481,
      "eval_rewards/margins": 3.2352709770202637,
      "eval_logps/chosen": -255.8983154296875,
      "eval_logps/rejected": -285.8782958984375,
      "eval_logits/chosen": -2.2702035903930664,
      "eval_logits/rejected": -2.2806055545806885,
      "epoch": 0.7111111111111111,
      "step": 100
    },
    {
      "loss": 1.3659,
      "grad_norm": 38.81193161010742,
      "learning_rate": 8.920178439890765e-06,
      "rewards/chosen": -3.709535598754883,
      "rewards/rejected": -6.586535453796387,
      "rewards/accuracies": 0.7112500071525574,
      "rewards/margins": 2.876999855041504,
      "logps/chosen": -260.8824157714844,
      "logps/rejected": -285.7748107910156,
      "logits/chosen": -2.283811569213867,
      "logits/rejected": -2.2854912281036377,
      "epoch": 0.8888888888888888,
      "step": 125
    },
    {
      "loss": 1.279,
      "grad_norm": 25.154436111450195,
      "learning_rate": 8.199842702516584e-06,
      "rewards/chosen": -3.3224799633026123,
      "rewards/rejected": -7.006523132324219,
      "rewards/accuracies": 0.7170050740242004,
      "rewards/margins": 3.6840426921844482,
      "logps/chosen": -253.4899139404297,
      "logps/rejected": -289.7911376953125,
      "logits/chosen": -2.3735172748565674,
      "logits/rejected": -2.3667707443237305,
      "epoch": 1.064,
      "step": 150
    },
    {
      "loss": 0.9892,
      "grad_norm": 30.313230514526367,
      "learning_rate": 7.343301470810809e-06,
      "rewards/chosen": -2.7946290969848633,
      "rewards/rejected": -6.027941703796387,
      "rewards/accuracies": 0.7587500214576721,
      "rewards/margins": 3.2333126068115234,
      "logps/chosen": -267.4257507324219,
      "logps/rejected": -294.7593688964844,
      "logits/chosen": -2.423922061920166,
      "logits/rejected": -2.4067628383636475,
      "epoch": 1.2417777777777779,
      "step": 175
    },
    {
      "loss": 1.0043,
      "grad_norm": 34.48381805419922,
      "learning_rate": 6.387014543809224e-06,
      "rewards/chosen": -2.7273800373077393,
      "rewards/rejected": -5.927495956420898,
      "rewards/accuracies": 0.7350000143051147,
      "rewards/margins": 3.2001149654388428,
      "logps/chosen": -263.5241394042969,
      "logps/rejected": -289.167724609375,
      "logits/chosen": -2.445981502532959,
      "logits/rejected": -2.427429437637329,
      "epoch": 1.4195555555555557,
      "step": 200
    },
    {
      "eval_loss": 1.1693894863128662,
      "eval_runtime": 216.9709,
      "eval_samples_per_second": 2.304,
      "eval_steps_per_second": 0.576,
      "eval_rewards/chosen": -2.833939552307129,
      "eval_rewards/rejected": -5.618758201599121,
      "eval_rewards/accuracies": 0.7440000176429749,
      "eval_rewards/margins": 2.784818649291992,
      "eval_logps/chosen": -253.77301025390625,
      "eval_logps/rejected": -282.85205078125,
      "eval_logits/chosen": -2.429116725921631,
      "eval_logits/rejected": -2.436530590057373,
      "epoch": 1.4195555555555557,
      "step": 200
    },
    {
      "loss": 0.7703,
      "grad_norm": 21.696584701538086,
      "learning_rate": 5.371687526669439e-06,
      "rewards/chosen": -2.328835964202881,
      "rewards/rejected": -6.607382774353027,
      "rewards/accuracies": 0.7762500047683716,
      "rewards/margins": 4.278546333312988,
      "logps/chosen": -258.0600891113281,
      "logps/rejected": -300.893798828125,
      "logits/chosen": -2.4347972869873047,
      "logits/rejected": -2.4203665256500244,
      "epoch": 1.5973333333333333,
      "step": 225
    },
    {
      "loss": 0.9093,
      "grad_norm": 27.231000900268555,
      "learning_rate": 4.340539143289655e-06,
      "rewards/chosen": -2.8076980113983154,
      "rewards/rejected": -6.045230865478516,
      "rewards/accuracies": 0.7637500166893005,
      "rewards/margins": 3.2375328540802,
      "logps/chosen": -271.091552734375,
      "logps/rejected": -301.9369812011719,
      "logits/chosen": -2.4326467514038086,
      "logits/rejected": -2.432579278945923,
      "epoch": 1.775111111111111,
      "step": 250
    },
    {
      "loss": 0.8249,
      "grad_norm": 22.26329803466797,
      "learning_rate": 3.3374615747377165e-06,
      "rewards/chosen": -2.466348886489868,
      "rewards/rejected": -5.948186874389648,
      "rewards/accuracies": 0.768750011920929,
      "rewards/margins": 3.481837749481201,
      "logps/chosen": -248.34129333496094,
      "logps/rejected": -289.9910888671875,
      "logits/chosen": -2.4653687477111816,
      "logits/rejected": -2.4417409896850586,
      "epoch": 1.952888888888889,
      "step": 275
    },
    {
      "loss": 0.701,
      "grad_norm": 22.59967803955078,
      "learning_rate": 2.4051521310939258e-06,
      "rewards/chosen": -2.078104257583618,
      "rewards/rejected": -5.716525077819824,
      "rewards/accuracies": 0.779187798500061,
      "rewards/margins": 3.638420820236206,
      "logps/chosen": -263.139404296875,
      "logps/rejected": -287.244873046875,
      "logits/chosen": -2.4573817253112793,
      "logits/rejected": -2.455850601196289,
      "epoch": 2.128,
      "step": 300
    },
    {
      "eval_loss": 1.0998563766479492,
      "eval_runtime": 216.6504,
      "eval_samples_per_second": 2.308,
      "eval_steps_per_second": 0.577,
      "eval_rewards/chosen": -2.578110456466675,
      "eval_rewards/rejected": -5.470443248748779,
      "eval_rewards/accuracies": 0.7459999918937683,
      "eval_rewards/margins": 2.8923325538635254,
      "eval_logps/chosen": -253.26132202148438,
      "eval_logps/rejected": -282.5554504394531,
      "eval_logits/chosen": -2.4608685970306396,
      "eval_logits/rejected": -2.466555118560791,
      "epoch": 2.128,
      "step": 300
    },
    {
      "loss": 0.6818,
      "grad_norm": 20.579648971557617,
      "learning_rate": 1.5832957845419583e-06,
      "rewards/chosen": -2.137848138809204,
      "rewards/rejected": -5.740914344787598,
      "rewards/accuracies": 0.7900000214576721,
      "rewards/margins": 3.6030657291412354,
      "logps/chosen": -247.66331481933594,
      "logps/rejected": -293.4840393066406,
      "logits/chosen": -2.472243309020996,
      "logits/rejected": -2.477854013442993,
      "epoch": 2.3057777777777777,
      "step": 325
    },
    {
      "loss": 0.6087,
      "grad_norm": 13.488537788391113,
      "learning_rate": 9.068759265665384e-07,
      "rewards/chosen": -1.991310477256775,
      "rewards/rejected": -6.408930778503418,
      "rewards/accuracies": 0.8087499737739563,
      "rewards/margins": 4.417620658874512,
      "logps/chosen": -258.1390686035156,
      "logps/rejected": -297.18048095703125,
      "logits/chosen": -2.484739303588867,
      "logits/rejected": -2.4598822593688965,
      "epoch": 2.4835555555555557,
      "step": 350
    },
    {
      "loss": 0.6829,
      "grad_norm": 34.84269332885742,
      "learning_rate": 4.046852540895446e-07,
      "rewards/chosen": -2.2685413360595703,
      "rewards/rejected": -5.753709316253662,
      "rewards/accuracies": 0.8100000023841858,
      "rewards/margins": 3.4851677417755127,
      "logps/chosen": -269.96856689453125,
      "logps/rejected": -298.7681884765625,
      "logits/chosen": -2.5034589767456055,
      "logits/rejected": -2.4846417903900146,
      "epoch": 2.6613333333333333,
      "step": 375
    },
    {
      "loss": 0.6526,
      "grad_norm": 29.659971237182617,
      "learning_rate": 9.810017062595322e-08,
      "rewards/chosen": -2.0613906383514404,
      "rewards/rejected": -5.841746807098389,
      "rewards/accuracies": 0.800000011920929,
      "rewards/margins": 3.7803561687469482,
      "logps/chosen": -260.1133117675781,
      "logps/rejected": -291.7719421386719,
      "logits/chosen": -2.4638969898223877,
      "logits/rejected": -2.4651920795440674,
      "epoch": 2.8391111111111114,
      "step": 400
    },
    {
      "eval_loss": 1.092212438583374,
      "eval_runtime": 216.9535,
      "eval_samples_per_second": 2.305,
      "eval_steps_per_second": 0.576,
      "eval_rewards/chosen": -2.4564526081085205,
      "eval_rewards/rejected": -5.237061977386475,
      "eval_rewards/accuracies": 0.7480000257492065,
      "eval_rewards/margins": 2.7806098461151123,
      "eval_logps/chosen": -253.01806640625,
      "eval_logps/rejected": -282.08868408203125,
      "eval_logits/chosen": -2.4701199531555176,
      "eval_logits/rejected": -2.4756546020507812,
      "epoch": 2.8391111111111114,
      "step": 400
    },
    {
      "train_runtime": 21497.736,
      "train_samples_per_second": 0.628,
      "train_steps_per_second": 0.02,
      "total_flos": 0.0,
      "train_loss": 1.0494402441290818,
      "epoch": 3.0,
      "step": 423
    }
  ],
  "output_dir": "./outputs/dpo_trial2/final"
}